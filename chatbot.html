<h1>Chatbot Project - A Lesson in AI and Natural Laguage Processing</h1> 

https://towardsdatascience.com/a-brief-introduction-to-intent-classification-96fda6b1f557

https://medium.com/analytics-vidhya/building-a-simple-chatbot-in-python-using-nltk-7c8c8215ac6e

https://zapier.com/blog/how-to-build-chat-bot/

https://medium.com/alex-attia-blog/build-a-first-simple-slack-bot-with-python-5392ef359835

https://medium.com/@gk_/how-chat-bots-work-dfff656a35e2

https://pythonhosted.org/Pyro4/



Purpose
Create a well planned chatbot application with context. We will 
design a framework for planning the bot as well as a conversational model 
for an island moped shop. The chatbot will handle simple questions regarding 
hours of operation, reservation options, etc. We also wish to address 
any inquiries into same day rentals.

STEPS TO COMPLETE CHATBOT
We will perform the following:

1. Transform conversational intent definitions to a Tensorflow model
2. Build a chatbot framework to process responses
3. Show how basic context can be incorporated into our response processor

TECHNOLOGIES UTILIZED

TFLearn
http://tflearn.org/

Tensorflow
https://www.tensorflow.org/

Python
https://www.python.org/

iPython Notebook
https://ipython.org/notebook.html

STEP 1: Transform conversational intent definitions to a Tensorflow model

A chatbot framework needs a structure in which conversational
intents are defined. A JSON file is a great tool for this challenge

E.G. JSON file https://github.com/ugik/notebooks/blob/master/intents.json

Three elements will be defined in each conversational intent:
1. a tag, which will have a unique name
2. patterns, which are sentence patterns for our neural network text classifier
3. response, which are comprised of example responses


Notebook for Step 1: https://github.com/ugik/notebooks/blob/master/Tensorflow%20chat-bot%20model.ipynb

  A. Import necessary tools and software
    # things we need for NLP
    import nltk
    from nltk.stem.lancaster import LancasterStemmer
    stemmer = LancasterStemmer()
    
    # things we need for Tensorflow
    import numpy as np
    import tflearn
    import tensorflow as tf
    import random

  B. After the intents JSON file is loaded, we can start building organized
  documents, words and classification classes.

    The lists of documents we crate are simmply sentences
    with each sentence being a list of stemmed words and each 
    document associated with an intent (=class)

    Tensorflow cannot process from documents of words,
    so we will tranform our data furthe into tensors of numbers.
    
    -----
    Our data is now shuffled. Tensorflow will use some of this
    mixed data to test our data to guage accuracy for a newly fitted
    model.

    If we look at a single x and y list element, we see "bag of words" arrays, one 
    for the intent pattern, the other for the intent class.

  C. We are all set to build our model.

    To complete this section of work, we'll save "pickel"
    our model and documents so the next notebook can use them.

  D. BUILDING THE CHATBOT FRAMEWORK

     We are building a simple state-machine to handle responses,
     using our intents model (from the previous step) as our classifier.
     This, in esssence, is what makes a chatbot function.

     After loading the importd, we "unpickle" our mosel and documents
     and reload our intents file. 
     ***Note: Our chatbot framework is seperate from our model build-
     the model does not have to be rebuilt unless the intent pattern change.

     We then load our saved Tensorflow (tflearn framework) model.
     Notice you forst neeed to define the Tensorflow model structure just as we 
     did in the previous section.

     We need a way to produce a bag-of-words from user input. This is the same technique
     as we used earlier to create our training documents.

     We are now ready to build our processor.

     Each sentence passed to response () is classified. Our classifier uses model.predict()
     and is lightning fast. the probabilities returned by the model
     are lined-up with our intents definitions to produce a list of potential responses.

     If one or more classifications are above threshold, we see
     if a tag matches an intent and then process that.
     We'll treat our classification list as a stack and 
     pop off the stack looking for a suitable match until we find one, or it's empty.

     Let's look at a classification example, the most likely tag and its probability
     are returned.

     Notice that ‘is your shop open today?’ is not one of the 
     patterns for this intent: “patterns”: [“Are you open today?”, 
     “When do you open today?”, “What are your hours today?”] however the terms ‘open’ 
     and ‘today’ proved irresistible to our model (they are prominent in the chosen intent).
     We can now generate a chatbot response from user-input:

     And other context-free responses…

 STEP 4: ADD IN BASIC CONTEXTUALIZATION

     We want to handle a question about renting a moped and ask if the rental is for today. 
     That clarification question is a simple contextual response. If the user responds ‘today’ 
     and the context is the rental timeframe then it’s best they call the rental company’s 1–800 #. 
     This allows for prompt same-day service.

     To achieve this we will add the notion of ‘state’ to our framework. 
     This is comprised of a data-structure to maintain state and specific 
     code to manipulate it while processing intents.

     Because the state of our state-machine needs to be easily persisted, restored, copied, etc. 
     it’s important to keep it all in a data structure such as a dictionary.

     Here’s our response process with basic contextualization:

     Our context state is a dictionary, it will contain state for each user. 
     We’ll use some unique identified for each user (eg. cell #). 
     This allows our framework and state-machine to maintain state for multiple users simultaneously.

     # create a data structure to hold user context
    context = {}

    The context handlers are added within the intent processing flow, shown again below:

        If an intent wants to set context, it can do so:

        {“tag”: “rental”,
        “patterns”: [“Can we rent a moped?”, “I’d like to rent a moped”, … ],
        “responses”: [“Are you looking to rent today or later this week?”],
        “context_set”: “rentalday”
        }
        If another intent wants to be contextually linked to a context, it can do that:

        {“tag”: “today”,
        “patterns”: [“today”],
        “responses”: [“For rentals today please call 1–800-MYMOPED”, …],
        “context_filter”: “rentalday”
        }

    In this way, if a user just typed ‘today’ out of the blue (no context), 
    our ‘today’ intent won’t be processed. If they enter ‘today’ as a response 
    to our clarification question (intent tag:‘rental’) then the intent is processed.

        Our context state changed:

    We defined our ‘greeting’ intent to clear context, as is often the case with small-talk. 
    We add a ‘show_details’ parameter to help us see inside.

    Let’s try the ‘today’ input once again, a few notable things here…
        
    First, our response to the context-free ‘today’ was different. 
    Our classification produced 2 suitable intents, and the ‘opentoday’ was selected because the ‘today’ intent, 
    while higher probability, was bound to a context that no longer applied. Context matters!

    Consider...
        That’s right, your chatbot will no longer be happy as a stateless service.

        Unless you want to reconstitute state, reload your model and documents — 
        with every call to your chatbot framework, you’ll need to make it stateful.

        This isn’t that difficult. You can run a stateful chatbot framework in its 
        own process and call it using an RPC (remote procedure call) or RMI (remote method invocation), I recommend Pyro.

        The user-interface (client) is typically stateless, eg. HTTP or SMS.

          Your chatbot client will make a Pyro function call, which your stateful service will handle. Voila!
        
          Here’s a step-by-step guide to build a Twilio SMS chatbot client, and here’s one for FB Messenger.

    A NOTE ABOUT STATE information
    All state information must be placed in a data structure such as a dictionary, easily persisted, reloaded, 
    or copied atomically. Each user’s conversation will carry context which will be carried statefully for that user. 
    The user ID can be their cell #, a Facebook user ID, or some other unique identifier.

    There are scenarios where a user’s conversational state needs to be copied (by value) and then restored as a result 
    of intent processing. If your state machine carries state across variables within your framework you will have a 
    difficult time making this work in real life scenarios.
      
    So now you have a chatbot framework, a recipe for making it a stateful service, and a starting-point for adding context. 
    Most chatbot frameworks in the future will treat context seamlessly.

    Think of creative ways for intents to impact and react to different 
    context settings. Your users’ context dictionary can contain a wide-variety 
    of conversation context.


Think of something like stripped-down Slack.
People enter without authentication and are assigned a name, stored for when they come back. The chat history is stored and retrieved from a database. You can add notifications (pop up or sound) in the browser for when someone sends a new message.

We’ll build a chatbot framework using Tensorflow and add some context handling to show how this can be approached.


Bots often lack context
https://chatbotsmagazine.com/maintaining-context-in-chatbots-2016b6a5b7c6

Designing a chatbot framework
https://chatbotsmagazine.com/design-framework-for-chatbots-aa27060c4ea3

Class = 

JSON File =  JSON is short for JavaScript Object Notation, and is a way to store information in an organized, easy-to-access manner. 
  In a nutshell, it gives us a human-readable collection of data that we can access in a really logical manner.
  To access the information stored in a variable we stored in a JSON file, we can simply refer to the name of the property we need. 
  Many sites are sharing data using JSON in addition to RSS feeds nowadays, and with good reason: JSON feeds can be loaded asynchronously 
  much more easily than XML/RSS.


AJAX = Asynchronous JavaScript And XML; AJAX is not a programming language, but rather just uses a combination of:
    -A browser built-in XMLHttpRequest object (to request data from a web server)
    -JavaScript and HTML DOM (to display or use the data). AJAX allows web pages to be updated asynchronously by 
     exchanging data with a web server behind the scenes. 
  This means that it is possible to update parts of a web page, without reloading the whole page.
  AJAX applications might use XML to transport data, but it is equally 
  common to transport data as plain text or JSON text.

XML= Extensible Markup Language (XML) is a markup language that defines a set of rules for encoding documents in a 
  format that is both human-readable and machine-readable. It is a software- and hardware-independent tool for 
  storing and transporting data. XML and HTML were designed with different goals. 
  -XML was designed to carry data - with focus on what data is 
  -HTML was designed to display data - with focus on how data looks
  -XML tags are not predefined like HTML tags are

HTML DOM=  (Document Object Model); when a web page is loaded, the browser creates a Document Object Model of the page.
The HTML DOM model is constructed as a tree of Objects (as seen below). 
With the object model, JavaScript gets all the power it needs to create dynamic HTML.



https://www.w3schools.com/js/pic_htmltree.gif


intents model
classifier
Neural Net
context handlers
stateless service
stateful

Sources:
https://www.w3schools.com/whatis/whatis_ajax.asp
https://www.w3schools.com/js/js_htmldom.asp
https://www.w3schools.com/xml/xml_whatis.asp
https://towardsdatascience.com/a-brief-introduction-to-intent-classification-96fda6b1f557

<!--
Tools
We’ll be using tflearn, a layer above tensorflow, and of course Python. As always we’ll use iPython notebook as a tool to facilitate our work.



  (larger picture)


  (med picture)


  (smallest picture)

  It has a learning curve. Agreed. But what doesn’t?

  It was a very liberating exercise to learn something methodically and then go on ahead and make a working proof of concept. I was feeling good.



<p>I started writing this article, I knew nothing about bots. I had a superficially working knowledge of AI and how supervised learning worked in general but to me NLP was just an acronym that meant Natural Language Processing. About half of the reasons why I started investigating chatbots was to learn more about the gaps I had in my knowledge of this particular play. Someone put it well —

How did making a bot make more business sense?

he bot industry is in its infancy right now and they are all competing for the same thing — to find the next killer app that makes chatbots mainstream. There are no reigning champions in the chatbot domain as of now. The whole industry is a level playing field.

I talked with a lot of people to investigate how far we really are into this future. It was an educational ride just I had imagined. Common consensus with the experts that I talked to put the timeframe to about two years to five years until we see a really killer app for the chatbot platform. The technology still in its evolution, it is safe to say that the even the best chatbots of today can grow obsolete because of newer announcements in AI and NLP research.

It means that if the right idea struck, anyone could make the potential killer app. This revelation was highly motivating. Right now, the chatbots I played with seemed to be doing quite simple things but in all essence they were just replacement for the GUI. Two things that I noticed in particular with the good ones were:

If performing a task took longer than 2 steps on UI, chatbots provided a much better user experience.
Places in the UI where the task was just a simple search and tap, chatbots seemed redundant.</p>

In summary:
Whether you write a UI or a chatbot, it doesn’t really matter. The user will come to your solution only if it saves time.

The decision to build a chatbot instead of an app does indeed carry business merit. It saves time in longer than expected UI flows. The next part of my journey was actually making a bot to see how deep the waters really go.

Building a chatbot was like solving a reasonably-sized jigsaw puzzle for me. I just had to find the right pieces and the tools needed to build it. While I had some of the puzzle at an arm's length, I was still confused on where to start. I had a checklist of two items —

1. Bot should talk like a person: meaning that it should understand natural language.
2. Bot should be able to solve a non-trivial use case: meaning that it should do something that takes more than two steps to do in UI (business merit).


aking a chatbot for my own personal use opened me to a world of possibilities. People are solving so many of their problems with clustered UI like booking travel tickets, hotels, movie tickets, ordering food, etc. The user experience can be improved by leaps and bounds by introducing a bot UI there. The newness of the platform really excites me, to be honest. It’s the age when new Facebooks and Whatsapps emerge out of darkness.

I believe in a world not far away in time, everything would be done via a conversational bot like in the movie, Her. It would be more efficient than even a single tap on your smartphone screen. I wouldn’t advise falling in love with your Samantha, though. ;)

Jokes apart, the chatbot play is definitely an emerging trend. Everyone is debating whether it would last or not. But trends don’t live or die by their own. It’s people that make or unmake them.

I believe hype is an instrument that brings obscurity into mainstream. The industry is just learning what all it can do with this relatively new tech. It’s a bet worth taking as a businessman and a skill worth learning as an engineer.

After all, the best bots are yet to be made.-->

